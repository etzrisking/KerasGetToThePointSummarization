{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import one_hot,Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Flatten ,Embedding,Input\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import LSTM, Bidirectional, concatenate, Add, Lambda\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "EMBEDDING_FILE=r'C:\\Users\\TanZhenR\\Desktop\\Projects\\Standard\\Text Embeddings\\Glove/glove.6B.100d.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE, encoding=\"utf8\"))\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_SIZE = 100\n",
    "LATENT_DIM = 50\n",
    "VOC_SIZE = len(embeddings_index)\n",
    "\n",
    "# Embedding\n",
    "word_index = embeddings_index.keys()\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (VOC_SIZE, EMBED_SIZE))\n",
    "for i, word in enumerate(word_index):\n",
    "    if len(re.findall('[,.?!@#$%^&*()-+_={}|:;]', word)) == 0:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\TanZhenR\\AppData\\Local\\Continuum\\anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\TanZhenR\\AppData\\Local\\Continuum\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Encoder embedding\n",
    "enc_input = Input(shape=(None,), name='EncoderInputLayer') \n",
    "enc_emb_layer = Embedding(VOC_SIZE, EMBED_SIZE, weights=[embedding_matrix], trainable=False, name='EncoderEmbedLayer')\n",
    "enc_emb_output = enc_emb_layer(enc_input)\n",
    "\n",
    "#BiLSTM encoder\n",
    "enc_lstm_layer = Bidirectional(LSTM(LATENT_DIM, return_sequences = True, return_state = True, dropout = 0.3), name='EncBiLSTMLayer')\n",
    "enc_output, fw_h, fw_c, bw_h, bw_c = enc_lstm_layer(enc_emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat states for attn_dist\n",
    "enc_state_h = concatenate([fw_h, bw_h], name='EncConcatH')\n",
    "enc_state_c = concatenate([fw_c, bw_c], name='EncConcatC')\n",
    "\n",
    "enc_state_h = Dense(LATENT_DIM*2, name='EncDenseH')(enc_state_h)\n",
    "enc_state_c = Dense(LATENT_DIM*2, name='EncDenseC')(enc_state_c)\n",
    "\n",
    "# dec initial state\n",
    "dec_ini_state = [enc_state_h, enc_state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "dec_input = Input(shape=(None,), name='DecoderInput') \n",
    "dec_emb_layer = Embedding(VOC_SIZE, EMBED_SIZE, weights=[embedding_matrix], trainable=False, name='DecoderEmbedLayer')\n",
    "dec_emb_output = dec_emb_layer(dec_input)\n",
    "\n",
    "# decoder LSTM\n",
    "dec_lstm_layer = LSTM(LATENT_DIM*2, return_sequences=True, return_state=True, dropout=0.3, name='DecLSTMLayer')\n",
    "dec_output, state_h, state_c = dec_lstm_layer(dec_emb_output, initial_state=dec_ini_state)\n",
    "dec_state = concatenate([state_h, state_c], name='DecConcatHC')\n",
    "\n",
    "# decoder feature\n",
    "dec_feat = Lambda(lambda x: K.expand_dims(x, axis=1), name='DecFeat1')(dec_state)\n",
    "dec_feat = Lambda(lambda x: K.expand_dims(x, axis=1), name='DecFeat2')(dec_feat)\n",
    "\n",
    "# decoder Distribution\n",
    "dec_dist = Dense(VOC_SIZE, activation='softmax', name='DecDistribution')(dec_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Mechanism\n",
    "\n",
    "# reshape enc_output\n",
    "enc_feat = Lambda(lambda x: K.expand_dims(x, axis=2), name='EncFeat1')(enc_output)\n",
    "enc_feat = Dense(EMBED_SIZE*2, name='EncFeat2')(enc_feat)\n",
    "\n",
    "# attention distribution\n",
    "attn_dist = Lambda(lambda x: x[0] + x[1], name='AttnDist1')([enc_feat, dec_feat])\n",
    "attn_dist = Dense(EMBED_SIZE*2, name='AttnDist2')(attn_dist)\n",
    "attn_dist = Lambda(lambda x: K.sum(x, axis=[2,3]), name='AttnDist3')(attn_dist)\n",
    "\n",
    "# encoding distribution\n",
    "enc_dist = Lambda(lambda x: x[0] * x[1], name='EncDist1')([attn_dist, enc_emb_output])\n",
    "enc_dist = Dense(VOC_SIZE, activation='softmax', name='EncDist2')(enc_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pgen\n",
    "pgen = concatenate([concatenate(dec_ini_state), dec_state], name='PGen1')\n",
    "pgen = Dense(1, activation='linear', name='PGen2')(pgen)\n",
    "\n",
    "# overall distribution\n",
    "overall_dist = Lambda(lambda x: (1-x[2])*x[0] + x[2]*x[1], name='Output')([enc_dist, dec_dist, pgen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "EncoderInputLayer (InputLayer)  (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EncoderEmbedLayer (Embedding)   (None, None, 100)    40000000    EncoderInputLayer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "EncBiLSTMLayer (Bidirectional)  [(None, None, 100),  60400       EncoderEmbedLayer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "DecoderInput (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EncConcatH (Concatenate)        (None, 100)          0           EncBiLSTMLayer[0][1]             \n",
      "                                                                 EncBiLSTMLayer[0][3]             \n",
      "__________________________________________________________________________________________________\n",
      "EncConcatC (Concatenate)        (None, 100)          0           EncBiLSTMLayer[0][2]             \n",
      "                                                                 EncBiLSTMLayer[0][4]             \n",
      "__________________________________________________________________________________________________\n",
      "DecoderEmbedLayer (Embedding)   (None, None, 100)    40000000    DecoderInput[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "EncDenseH (Dense)               (None, 100)          10100       EncConcatH[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "EncDenseC (Dense)               (None, 100)          10100       EncConcatC[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "DecLSTMLayer (LSTM)             [(None, None, 100),  80400       DecoderEmbedLayer[0][0]          \n",
      "                                                                 EncDenseH[0][0]                  \n",
      "                                                                 EncDenseC[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "DecConcatHC (Concatenate)       (None, 200)          0           DecLSTMLayer[0][1]               \n",
      "                                                                 DecLSTMLayer[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "EncFeat1 (Lambda)               (None, None, 1, 100) 0           EncBiLSTMLayer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "DecFeat1 (Lambda)               (None, 1, 200)       0           DecConcatHC[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "EncFeat2 (Dense)                (None, None, 1, 200) 20200       EncFeat1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecFeat2 (Lambda)               (None, 1, 1, 200)    0           DecFeat1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "AttnDist1 (Lambda)              (None, None, 1, 200) 0           EncFeat2[0][0]                   \n",
      "                                                                 DecFeat2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "AttnDist2 (Dense)               (None, None, 1, 200) 40200       AttnDist1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "AttnDist3 (Lambda)              (None, None)         0           AttnDist2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 200)          0           EncDenseH[0][0]                  \n",
      "                                                                 EncDenseC[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "EncDist1 (Lambda)               (None, None, 100)    0           AttnDist3[0][0]                  \n",
      "                                                                 EncoderEmbedLayer[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "PGen1 (Concatenate)             (None, 400)          0           concatenate_1[0][0]              \n",
      "                                                                 DecConcatHC[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "EncDist2 (Dense)                (None, None, 400000) 40400000    EncDist1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "DecDistribution (Dense)         (None, None, 400000) 40400000    DecLSTMLayer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "PGen2 (Dense)                   (None, 1)            401         PGen1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Output (Lambda)                 (None, None, 400000) 0           EncDist2[0][0]                   \n",
      "                                                                 DecDistribution[0][0]            \n",
      "                                                                 PGen2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 161,021,801\n",
      "Trainable params: 81,021,801\n",
      "Non-trainable params: 80,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[enc_input, dec_input], outputs=overall_dist)\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
