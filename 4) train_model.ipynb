{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import one_hot,Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Flatten ,Embedding,Input\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import LSTM, Bidirectional, concatenate, Add, Lambda, RepeatVector, TimeDistributed\n",
    "from attention_decoder import AttentionDecoder\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = r'D:\\projects\\nlp\\embeddings'\n",
    "SAVE_BIN_DIR = r'D:\\projects\\nlp\\summarization\\stories\\all_bin'\n",
    "VOCAB_DIR = r'D:\\projects\\nlp\\summarization\\stories\\vocab'\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "EMBED_SIZE = EMBEDDING_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.{}d.txt'.format(EMBEDDING_DIM)), 'r', encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = pickle.load(open(os.path.join(VOCAB_DIR, 'vocab.pkl') , 'rb'))\n",
    "\n",
    "emb_mat = np.array(list(embeddings_index.values()))\n",
    "ave_emb = emb_mat.mean(axis=0)\n",
    "emb_matrix = np.array([np.zeros(len(ave_emb))] + [ave_emb] * len(word_index)) # 0 reserved for padding\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        emb_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOC_SIZE = len(emb_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Encoder embedding\n",
    "enc_input = Input(shape=(None,), name='EncoderInputLayer') \n",
    "enc_emb_layer = Embedding(VOC_SIZE, EMBED_SIZE, weights=[emb_matrix], trainable=False, name='EncEmbLayer') # Shared Embedding\n",
    "enc_emb_output = enc_emb_layer(enc_input) # [batchSize, NumOfWords_Enc, EMBED_SIZE]\n",
    "\n",
    "#BiLSTM encoder\n",
    "enc_lstm_layer = Bidirectional(LSTM(LATENT_DIM, return_sequences=True, return_state = True, dropout = 0.3), name='EncBiLSTMLayer')\n",
    "enc_output, fw_h, fw_c, bw_h, bw_c = enc_lstm_layer(enc_emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat states for attn_dist\n",
    "enc_state_h = concatenate([fw_h, bw_h], name='EncConcatH')\n",
    "enc_state_c = concatenate([fw_c, bw_c], name='EncConcatC')\n",
    "\n",
    "enc_state_h = Dense(LATENT_DIM*2, name='EncDenseH')(enc_state_h)\n",
    "enc_state_c = Dense(LATENT_DIM*2, name='EncDenseC')(enc_state_c)\n",
    "\n",
    "# dec initial state\n",
    "dec_ini_state = [enc_state_h, enc_state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "dec_input = Input(shape=(None,), name='DecoderInputLayer')\n",
    "dec_emb_layer = Embedding(VOC_SIZE, EMBED_SIZE, weights=[emb_matrix], trainable=False, name='DecoderEmbedLayer')\n",
    "dec_emb_output = dec_emb_layer(dec_input)\n",
    "\n",
    "# decoder LSTM\n",
    "dec_lstm_layer = LSTM(LATENT_DIM*2, return_sequences=True, return_state=True, dropout=0.3, name='DecLSTMLayer')\n",
    "dec_output, state_h, state_c = dec_lstm_layer(dec_emb_output, initial_state=dec_ini_state)\n",
    "dec_state = concatenate([state_h, state_c], name='DecConcatHC')\n",
    "\n",
    "# decoder feature\n",
    "dec_feat = Dense(LATENT_DIM, name='DecFeat1')(dec_state) # [batchSize, LATENT_DIM]\n",
    "#dec_feat = Lambda(lambda x: K.expand_dims(x, axis=1), name='DecFeat2')(dec_feat)\n",
    "#dec_feat = Lambda(lambda x: K.expand_dims(x, axis=1), name='DecFeat3')(dec_feat)\n",
    "\n",
    "# decoder Distribution\n",
    "dec_dist = Dense(VOC_SIZE, activation='softmax', name='DecDistribution')(dec_output) # [batchSize, NumOfWord_Dec, VOC_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Mechanism\n",
    "\n",
    "# reshape enc_output\n",
    "#enc_feat = Lambda(lambda x: K.expand_dims(x, axis=1), name='EncFeat1')(enc_output)\n",
    "enc_feat = Dense(LATENT_DIM, name='EncFeat2')(enc_output) # [batchSize, LATENT_DIM]\n",
    "\n",
    "# attention distribution\n",
    "attn_dist = Add(name='AttnDist1')([enc_feat, dec_feat])\n",
    "attn_dist = Dense(LATENT_DIM, name='AttnDist2')(attn_dist) # [batchSize, NumOfWords_Enc, LATENT_DIM]\n",
    "attn_dist = Lambda(lambda x: K.sum(x, axis=2), name='AttnDist3')(attn_dist)\n",
    "attn_dist = Lambda(lambda x: K.expand_dims(x, axis=2))(attn_dist)\n",
    "attn_dist = Lambda(lambda x: K.repeat_elements(x, rep=EMBED_SIZE, axis=2))(attn_dist)\n",
    "\n",
    "# context vector\n",
    "cntxt_vec = Lambda(lambda x: x[0] * x[1], name='ContextVect1')([attn_dist, enc_emb_output])\n",
    "cntxt_vec = TimeDistributed(Dense(LATENT_DIM), name='ContextVect2')(cntxt_vec)\n",
    "cntxt_vec = Lambda(lambda x: K.sum(x, axis=1), name='ContextVect3')(cntxt_vec)\n",
    "\n",
    "# HOW TO USE THE CONTEXT VECTOR????\n",
    "\n",
    "#enc_dist = Dense(VOC_SIZE, activation='softmax', name='EncDist2')(enc_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pgen\n",
    "pgen = concatenate([concatenate(dec_ini_state), dec_state], name='PGen1')\n",
    "pgen = Dense(1, activation='sigmoid', name='PGen2')(pgen)\n",
    "pgen = Lambda(lambda x: K.expand_dims(x, axis=1))(pgen)\n",
    "pgen_c =Lambda(lambda x: 1-x)(pgen)\n",
    "\n",
    "# overall distribution\n",
    "overall_dist_a = Lambda(lambda x: x[0]*x[1], name='Output_a')([enc_dist, pgen])\n",
    "overall_dist_b = Lambda(lambda x: x[0]*(1-x[1]), name='Output_b')([dec_dist, pgen])\n",
    "#overall_dist = Add()([overall_dist_a, overall_dist_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 100)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(inputs=[enc_input, dec_input], outputs=cntxt_vec)\n",
    "res = model.predict(x=[x,y0])\n",
    "#model.compile(loss=\"categorical_crossentropy\", \n",
    "#              optimizer='rmsprop',\n",
    "#             metrics=[\"accuracy\"])\n",
    "#model.fit(x=[x,y0], y = y1, epochs=1, verbose=1)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1511, 50001)\n",
      "(5, 53, 50001)\n"
     ]
    }
   ],
   "source": [
    "print(res[0].shape)\n",
    "print(res[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[enc_input, dec_input], outputs=overall_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = len(os.listdir(os.path.join(SAVE_BIN_DIR)))\n",
    "\n",
    "def pad(x, max_len, p_type='pre'):\n",
    "    x_len = len(x)\n",
    "    require = max_len - x_len\n",
    "    \n",
    "    if require < 0:\n",
    "        return x[:max_len]\n",
    "    \n",
    "    if p_type == 'pre':\n",
    "        return [0] * require + x\n",
    "    else:\n",
    "        return x + [0] * require   \n",
    "\n",
    "def tmp_cat(idx, VOCAB_SIZE):\n",
    "    zeros = np.zeros(VOCAB_SIZE)\n",
    "    zeros[idx] = 1\n",
    "    return zeros\n",
    "    \n",
    "def to_categorical(yi, VOCAB_SIZE):\n",
    "    return np.array([tmp_cat(idx, VOCAB_SIZE) for idx in yi])\n",
    "    \n",
    "def gen_xy(num_batches):\n",
    "    b = 0\n",
    "    \n",
    "    while True:\n",
    "        b = b % num_batches\n",
    "        b += 1\n",
    "        \n",
    "        filename = os.path.join(SAVE_BIN_DIR, 'story_highlight_{}.bin'.format(b))\n",
    "        [stories, highlights] = pickle.load(open(filename, \"rb\"))\n",
    "                \n",
    "        highlights_teacher = [y[:-1] for y in highlights]\n",
    "        highlights_answer = [y[1:] for y in highlights]\n",
    "        \n",
    "        # batch padding\n",
    "        b_max_len_x =  max([len(x) for x in stories])        \n",
    "        x = [pad(x, b_max_len_x, p_type='pre') for x in stories]\n",
    "        \n",
    "        b_max_len_y0 = max([len(y) for y in highlights_teacher])\n",
    "        y0 = [pad(y, b_max_len_y0, p_type='post') for y in highlights_teacher]\n",
    "        \n",
    "        b_max_len_y1 = max([len(y) for y in highlights_teacher])\n",
    "        y1 = [pad(y, b_max_len_y1, p_type='post') for y in highlights_answer]\n",
    "        \n",
    "        print('padding done {}'.format(b))\n",
    "        \n",
    "        # numpy array\n",
    "        x = np.array(x)\n",
    "        y0 = np.array(y0)\n",
    "        y1 = [to_categorical(yi, VOCAB_SIZE) for yi in y1]\n",
    "        y1 = np.array(y1)\n",
    "        \n",
    "        print('np done {}'.format(b))\n",
    "    \n",
    "    yield([x, y0], y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy(b_num, VOCAB_SIZE):\n",
    "    filename = os.path.join(SAVE_BIN_DIR, 'story_highlight_{}.bin'.format(b_num))\n",
    "    [stories, highlights] = pickle.load(open(filename, \"rb\"))\n",
    "\n",
    "    stories = stories[:5]\n",
    "    highlights = highlights[:5]\n",
    "\n",
    "    highlights_teacher = [y[:-1] for y in highlights]\n",
    "    highlights_answer = [y[1:] for y in highlights]\n",
    "\n",
    "    # batch padding\n",
    "    b_max_len_x =  max([len(x) for x in stories])        \n",
    "    x = [pad(x, b_max_len_x, p_type='pre') for x in stories]\n",
    "\n",
    "    b_max_len_y0 = max([len(y) for y in highlights_teacher])\n",
    "    y0 = [pad(y, b_max_len_y0, p_type='post') for y in highlights_teacher]\n",
    "\n",
    "    b_max_len_y1 = max([len(y) for y in highlights_teacher])\n",
    "    y1 = [pad(y, b_max_len_y1, p_type='post') for y in highlights_answer]\n",
    "    \n",
    "    print('padding done')\n",
    "\n",
    "    # numpy array\n",
    "    x = np.array(x)\n",
    "    y0 = np.array(y0)\n",
    "    y1 = [to_categorical(yi, VOCAB_SIZE) for yi in y1]\n",
    "    y1 = np.array(y1)\n",
    "    \n",
    "    print('np done')\n",
    "    \n",
    "    return([x, y0], y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer='rmsprop',\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding done\n",
      "np done\n",
      "[(5, 1511), (5, 53)]\n",
      "(5, 53, 50001)\n",
      "[(None, None), (None, None)]\n",
      "(None, None, 50001)\n"
     ]
    }
   ],
   "source": [
    "[x, y0], y1 = xy(1, VOC_SIZE)\n",
    "print([x.shape, y0.shape])\n",
    "print(y1.shape)\n",
    "print(model.input_shape)\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=[x,y0], y = y1, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "    gen_xy(num_batches),\n",
    "    steps_per_epoch=num_batches,\n",
    "    epochs=1,\n",
    "    verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
